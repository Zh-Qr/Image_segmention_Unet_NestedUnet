{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da287507-a3b8-4a6a-b51b-71ceebb59afb",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7753014d-8a29-4e99-9faa-dd2aadbd1d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境准备完毕\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adadelta, Nadam ,Adam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import  plot_model ,Sequence\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.losses import binary_crossentropy\n",
    "from scipy.ndimage import morphology as mp\n",
    "from PIL import Image,UnidentifiedImageError\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import shutil\n",
    "import os\n",
    "from glob import glob  # for getting list paths of image and labels\n",
    "from random import choice,sample\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 # saving and loading images\n",
    "\n",
    "print(\"环境准备完毕\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb26d33-d5f0-442b-a362-e5e8a9538e41",
   "metadata": {},
   "source": [
    "### 获取数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faef7d00-18e4-45d4-bdde-3a7c02aad687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_img_dir = '../../autodl-tmp/Endovis18/Train/images/' \n",
    "train_mask_dir = '../../autodl-tmp/Endovis18/Train/pixeled_annotations_train/'\n",
    "\n",
    "train_imgs = os.listdir(train_img_dir)\n",
    "train_masks = os.listdir(train_mask_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5540b1e1-9c3a-442c-a5de-65f8f226fdd6",
   "metadata": {},
   "source": [
    "### 数据对齐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbed751d-afcc-4a8a-8c2b-0bb6c82550d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images and masks are not equal.\n",
      "Extra images: {'seq_1_frame025.png'}\n",
      "Extra masks: {'seq_10_frame044.png', 'seq_10_frame045.png', 'seq_10_frame049.png', 'seq_10_frame047.png', 'seq_10_frame048.png', 'seq_10_frame046.png'}\n",
      "Updated number of images: 2228\n",
      "Updated number of masks: 2228\n",
      "2228\n",
      "2228\n"
     ]
    }
   ],
   "source": [
    "if len(train_imgs) != len(train_masks):\n",
    "    print(\"The number of images and masks are not equal.\")\n",
    "\n",
    "    # 使用文件名，因为列表直接包含文件名\n",
    "    img_set = set(train_imgs)\n",
    "    mask_set = set(train_masks)\n",
    "\n",
    "    extra_imgs = img_set - mask_set\n",
    "    extra_masks = mask_set - img_set\n",
    "\n",
    "    print(\"Extra images:\", extra_imgs)\n",
    "    print(\"Extra masks:\", extra_masks)\n",
    "\n",
    "    # 从图像和掩码列表中移除多余的条目\n",
    "    train_imgs = [img for img in train_imgs if img not in extra_imgs]\n",
    "    train_masks = [mask for mask in train_masks if mask not in extra_masks]\n",
    "\n",
    "    print(\"Updated number of images:\", len(train_imgs))\n",
    "    print(\"Updated number of masks:\", len(train_masks))\n",
    "\n",
    "\n",
    "print(len(train_imgs))\n",
    "print(len(train_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c9d1db-1baf-4159-890f-7148374edefa",
   "metadata": {},
   "source": [
    "### 划分数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1feaee-50c6-4671-a5d3-9455b68abf86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1938\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "val_img_dir =  train_img_dir\n",
    "val_mask_dir = train_mask_dir\n",
    "\n",
    "\n",
    "train_imgs,val_imgs,train_masks,val_masks =  train_test_split(train_imgs, train_masks, test_size=0.13, random_state=42)\n",
    "\n",
    "\n",
    "print(len(train_masks))\n",
    "print(len(val_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d877a7-63c1-4350-9d03-d9db1f4b713a",
   "metadata": {},
   "source": [
    "### 数据集加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d43ed8f7-d6e8-413a-90c2-43b453deb5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batch_size = 8\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    \n",
    "    def __init__(self, images,image_dir,labels,label_dir ,batch_size, dim=(224,224,3) ,shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.images = images\n",
    "        self.image_dir = image_dir\n",
    "        self.labels = labels\n",
    "        self.label_dir = label_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.images) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [k for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.images))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        batch_imgs = list()\n",
    "        batch_labels = list()\n",
    "\n",
    "        # Generate data\n",
    "        for i in list_IDs_temp:\n",
    "#             degree=np.random.random() * 360\n",
    "            # Store sample\n",
    "            img = load_img(self.image_dir + self.images[i] ,target_size=self.dim)\n",
    "            img = img_to_array(img)/255.\n",
    "#             img = ndimage.rotate(img, degree)\n",
    "#             print(img)\n",
    "            batch_imgs.append(img)\n",
    "           # Store class\n",
    "            label = load_img(self.label_dir + self.labels[i] ,target_size=self.dim)\n",
    "            label = img_to_array(label)[:,:,0]\n",
    "            label = label != 0\n",
    "            label = mp.binary_erosion(mp.binary_erosion(label))\n",
    "            label = mp.binary_dilation(mp.binary_dilation(mp.binary_dilation(label)))\n",
    "            label = np.expand_dims((label)*1 , axis=2)\n",
    "            batch_labels.append(label)\n",
    "            \n",
    "        return np.array(batch_imgs,dtype = np.float32 ) ,np.array(batch_labels , dtype = np.float32 )\n",
    "    \n",
    "train_generator = DataGenerator(train_imgs,train_img_dir,train_masks,train_mask_dir,batch_size=num_batch_size, dim=(224,224,3) ,shuffle=True)\n",
    "train_steps = train_generator.__len__()\n",
    "\n",
    "val_generator = DataGenerator(val_imgs,val_img_dir,val_masks,val_mask_dir,batch_size=num_batch_size, dim=(224,224,3) ,shuffle=True)\n",
    "val_steps = val_generator.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4678652-3e48-4889-ae9d-34f9f474301a",
   "metadata": {},
   "source": [
    "### 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c85b059-3080-4d34-b28b-1b225014257f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n",
    "    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n",
    "    y = concatenate([y, residual], axis=3)\n",
    "    y = conv_block(y, nfilters)\n",
    "    return y\n",
    "\n",
    "\n",
    "def Unet(h, w, filters):\n",
    "# down\n",
    "    input_layer = Input(shape=(h, w, 3), name='image_input')\n",
    "    conv1 = conv_block(input_layer, nfilters=filters)\n",
    "    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = conv_block(conv1_out, nfilters=filters*2)\n",
    "    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = conv_block(conv2_out, nfilters=filters*4)\n",
    "    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = conv_block(conv3_out, nfilters=filters*8)\n",
    "    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv4_out = Dropout(0.5)(conv4_out)\n",
    "    conv5 = conv_block(conv4_out, nfilters=filters*16)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "# up\n",
    "    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n",
    "    deconv6 = Dropout(0.5)(deconv6)\n",
    "    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n",
    "    deconv7 = Dropout(0.5)(deconv7) \n",
    "    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n",
    "    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n",
    "    output_layer = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(deconv9)\n",
    "    # using sigmoid activation for binary classification\n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbee69e-e348-48b4-b3f7-14d8469aa24f",
   "metadata": {},
   "source": [
    "### 实例化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee3b7d14-8795-4ee4-8b75-9fa8e6f7e9da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 20:33:15.181419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9797 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:41:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = Unet(224 , 224 , 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee759315-faf7-4fad-8d9a-205f716e4991",
   "metadata": {},
   "source": [
    "### 设置评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6a20491-0ff8-4637-bba1-0dde3405349f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    return K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a5e2f8-4808-429b-b15e-e8f366e7a954",
   "metadata": {},
   "source": [
    "###  网络编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d81ecdcc-2e79-4b3f-b06d-a74196041eaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, iou, recall, precision])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d30f6-3690-4078-98ce-2beedefa7a58",
   "metadata": {},
   "source": [
    "###  模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0662e1-23a6-4a6e-9492-dc1e02881974",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 40\n",
    "results = model.fit(train_generator, steps_per_epoch=train_steps,epochs=num_epoch,callbacks=callbacks,validation_data=val_generator,validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122b306-8510-417a-a6a0-e0a1b4993d50",
   "metadata": {},
   "source": [
    "### 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2141f64c-ad3a-4144-8ce6-cef535fcee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_data = results.history\n",
    "df = pd.DataFrame(history_data)\n",
    "df.to_csv('result/training_history.csv')\n",
    "# 保存整个模型，包括结构、权重和训练配置\n",
    "model.save('result/complete_model.h5')\n",
    "# 保存模型的权重\n",
    "model.save_weights('result/complete_model_weights_only.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
